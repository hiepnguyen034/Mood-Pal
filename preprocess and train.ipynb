{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'whats up'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = '0\\t\\twhats up'\n",
    "string = re.sub(re.compile('\\d*\\d*\\t'),\"\",string)\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('review.csv',encoding='latin-1', sep='\\n',header=None)  \n",
    "data['label']=data[0].str.extract('(\\d)',expand=True)\n",
    "data[0]=[re.sub(re.compile('\\d'),\"\",string) for string in data[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]=[re.sub(re.compile('\\t'),\"\",string) for string in data[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns=['text','label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7081</th>\n",
       "      <td>Brokeback Mountain was boring.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7082</th>\n",
       "      <td>So Brokeback Mountain was really depressing.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7083</th>\n",
       "      <td>As I sit here, watching the MTV Movie Awards, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7084</th>\n",
       "      <td>Ok brokeback mountain is such a horrible movie.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7085</th>\n",
       "      <td>Oh, and Brokeback Mountain was a terrible movie.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text label\n",
       "7081                     Brokeback Mountain was boring.     0\n",
       "7082       So Brokeback Mountain was really depressing.     0\n",
       "7083  As I sit here, watching the MTV Movie Awards, ...     0\n",
       "7084    Ok brokeback mountain is such a horrible movie.     0\n",
       "7085   Oh, and Brokeback Mountain was a terrible movie.     0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = pd.read_csv('train.csv',encoding='latin-1')\n",
    "data_2['Text']=[re.sub(re.compile('@&*\\w+\\d*'),\"\",string) for string in data_2['SentimentText']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99984</th>\n",
       "      <td>99996</td>\n",
       "      <td>0</td>\n",
       "      <td>@Cupcake  seems like a repeating problem   hop...</td>\n",
       "      <td>seems like a repeating problem   hope you're...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99985</th>\n",
       "      <td>99997</td>\n",
       "      <td>1</td>\n",
       "      <td>@cupcake__ arrrr we both replied to each other...</td>\n",
       "      <td>arrrr we both replied to each other over diff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99986</th>\n",
       "      <td>99998</td>\n",
       "      <td>0</td>\n",
       "      <td>@CuPcAkE_2120 ya i thought so</td>\n",
       "      <td>ya i thought so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99987</th>\n",
       "      <td>99999</td>\n",
       "      <td>1</td>\n",
       "      <td>@Cupcake_Dollie Yes. Yes. I'm glad you had mor...</td>\n",
       "      <td>Yes. Yes. I'm glad you had more fun with me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99988</th>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>@cupcake_kayla haha yes you do</td>\n",
       "      <td>haha yes you do</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ItemID  Sentiment                                      SentimentText  \\\n",
       "99984   99996          0  @Cupcake  seems like a repeating problem   hop...   \n",
       "99985   99997          1  @cupcake__ arrrr we both replied to each other...   \n",
       "99986   99998          0                     @CuPcAkE_2120 ya i thought so    \n",
       "99987   99999          1  @Cupcake_Dollie Yes. Yes. I'm glad you had mor...   \n",
       "99988  100000          1                    @cupcake_kayla haha yes you do    \n",
       "\n",
       "                                                    Text  \n",
       "99984    seems like a repeating problem   hope you're...  \n",
       "99985   arrrr we both replied to each other over diff...  \n",
       "99986                                   ya i thought so   \n",
       "99987      Yes. Yes. I'm glad you had more fun with me.   \n",
       "99988                                   haha yes you do   "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_2['label']=data_2[0].str.extract('(\\d)',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_2['text']=[re.sub(re.compile('\\d*\\d*\\t'),\"\",string) for string in data_2[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2=data_2.drop(['ItemID','SentimentText'],axis=1)\n",
    "data_2.columns=['label','text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0                       is so sad for my APL frie...\n",
       "1      0                     I missed the New Moon trail...\n",
       "2      1                            omg its already 7:30 :O\n",
       "3      0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "4      0           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2=data_2[['text','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=pd.concat([data,data_2],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['text']=[re.sub(re.compile('@'),\"\",string) for string in dataset['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I thought you wanted a boys day.  I wanted to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&amp;quot;The needs of the many outweigh the needs...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zombies do write theses, its' just that they'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i checked my mail this week too  i must have ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>morning, what a grand one at that!!!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I love Brokeback Mountain....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>i didnt like mesa... it wasn't as good as i'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>anymommy bummer... no more labor pains... but...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Aw! I think i remember you telling me that! T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I thought u didn't drink. I feel played,   wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>http://bit.ly/qcm2V i bet u can see this</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>having fun watching the links! They are prett...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I have it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>*giggles to herself* after seeing Joans stalke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>As a hockey fan w/ no clue re: win32 , I am S...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LAKERS.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I'm looking at our Rhythm Inc. Trip to Huntin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>its not at all is it  sad times.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hey I'll be online in like 30 min, speak soon!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Go Yanks! And bring a poncho...rain for the n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LOL I know the feeling  you got a db backend ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Oh my God, I've been having headaches every d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dudeee i LOVED brokeback mountain!!!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ok ill try that thx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Tom Papa is hilarious. He had his own sitcom ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>unfortunately! i sent you a facebook msg. got...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>#Bones Spoilers: New twitter format. Check it ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>http://twitpic.com/68s6o - nawww you are so c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Great thing to remember when all your pieces ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>#twalk  its all going very well, trainers are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107045</th>\n",
       "      <td>aww  thats like when welker got crushed by th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107046</th>\n",
       "      <td>i love you too baby girl  and i'm sorry i am ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107047</th>\n",
       "      <td>you can surround me anyday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107048</th>\n",
       "      <td>that's good. Med told me nothing today.  wast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107049</th>\n",
       "      <td>ummm, i don't see anything....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107050</th>\n",
       "      <td>UR BF I GUESS LOL...OR THAT NIGGA TONY DAHSAR...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107051</th>\n",
       "      <td>dumbass  shame though, no worries, just wante...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107052</th>\n",
       "      <td>I enjoyed it too.  I wish there was more Brya...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107053</th>\n",
       "      <td>Mission Impossible  is astonishingly good, fat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107054</th>\n",
       "      <td>my uncle picked up some there yesterday 2lbs ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107055</th>\n",
       "      <td>http://bit.ly/gFHc4  - I don't really want a ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107056</th>\n",
       "      <td>don't forget the   whoever...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107057</th>\n",
       "      <td>I automatically get up at 5-7, no matter what.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107058</th>\n",
       "      <td>agreed on twi-tour! Thanks for reading blog a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107059</th>\n",
       "      <td>the fed-ex guy came to the door, so i ran to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107060</th>\n",
       "      <td>sigh,no, i am just not up to it  and it's lik...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107061</th>\n",
       "      <td>try to have fun x</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107062</th>\n",
       "      <td>oh your lucky!! its like FREEZING heree</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107063</th>\n",
       "      <td>Night night &amp;quot;Amy&amp;quot; (incognito)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107064</th>\n",
       "      <td>- or else, there's not much we can do with In...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107065</th>\n",
       "      <td>thx for the mention!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107066</th>\n",
       "      <td>i LOVE abercrombie and fitch.... thats why i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107067</th>\n",
       "      <td>So as felicia's mom is cleaning the table, fel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107068</th>\n",
       "      <td>I was about 19 and. Got claustrophobic and ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107069</th>\n",
       "      <td>At least Telemundo could leave this baby ali...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107070</th>\n",
       "      <td>not nice.  ohh, andy murray win wimbeldon, i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107071</th>\n",
       "      <td>perhaps you should get a holiday home in the ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107072</th>\n",
       "      <td>nightnight my fellow Cappster.....lol sleep t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107073</th>\n",
       "      <td>i know i'm late.....but THANKS!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107074</th>\n",
       "      <td>I can hate \" Da Vinci Code \" without even touc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107075 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text label\n",
       "0        I thought you wanted a boys day.  I wanted to...     0\n",
       "1       &quot;The needs of the many outweigh the needs...     0\n",
       "2        Zombies do write theses, its' just that they'...     1\n",
       "3        i checked my mail this week too  i must have ...     0\n",
       "4                  morning, what a grand one at that!!!!      1\n",
       "5                           I love Brokeback Mountain....     1\n",
       "6         i didnt like mesa... it wasn't as good as i'...     0\n",
       "7        anymommy bummer... no more labor pains... but...     1\n",
       "8        Aw! I think i remember you telling me that! T...     0\n",
       "9        I thought u didn't drink. I feel played,   wh...     0\n",
       "10              http://bit.ly/qcm2V i bet u can see this      1\n",
       "11       having fun watching the links! They are prett...     1\n",
       "12                                             I have it      0\n",
       "13      *giggles to herself* after seeing Joans stalke...     1\n",
       "14       As a hockey fan w/ no clue re: win32 , I am S...     0\n",
       "15                                               LAKERS.      1\n",
       "16       I'm looking at our Rhythm Inc. Trip to Huntin...     0\n",
       "17                       its not at all is it  sad times.     0\n",
       "18        hey I'll be online in like 30 min, speak soon!      1\n",
       "19       Go Yanks! And bring a poncho...rain for the n...     1\n",
       "20       LOL I know the feeling  you got a db backend ...     0\n",
       "21       Oh my God, I've been having headaches every d...     0\n",
       "22                  dudeee i LOVED brokeback mountain!!!!     1\n",
       "23                                   ok ill try that thx      1\n",
       "24       Tom Papa is hilarious. He had his own sitcom ...     0\n",
       "25       unfortunately! i sent you a facebook msg. got...     0\n",
       "26      #Bones Spoilers: New twitter format. Check it ...     1\n",
       "27       http://twitpic.com/68s6o - nawww you are so c...     1\n",
       "28       Great thing to remember when all your pieces ...     1\n",
       "29      #twalk  its all going very well, trainers are ...     1\n",
       "...                                                   ...   ...\n",
       "107045   aww  thats like when welker got crushed by th...     0\n",
       "107046   i love you too baby girl  and i'm sorry i am ...     1\n",
       "107047                        you can surround me anyday      1\n",
       "107048   that's good. Med told me nothing today.  wast...     0\n",
       "107049                    ummm, i don't see anything....      0\n",
       "107050   UR BF I GUESS LOL...OR THAT NIGGA TONY DAHSAR...     1\n",
       "107051   dumbass  shame though, no worries, just wante...     1\n",
       "107052   I enjoyed it too.  I wish there was more Brya...     1\n",
       "107053  Mission Impossible  is astonishingly good, fat...     1\n",
       "107054   my uncle picked up some there yesterday 2lbs ...     1\n",
       "107055   http://bit.ly/gFHc4  - I don't really want a ...     1\n",
       "107056                     don't forget the   whoever...      1\n",
       "107057    I automatically get up at 5-7, no matter what.      0\n",
       "107058   agreed on twi-tour! Thanks for reading blog a...     1\n",
       "107059   the fed-ex guy came to the door, so i ran to ...     0\n",
       "107060   sigh,no, i am just not up to it  and it's lik...     0\n",
       "107061                                  try to have fun x     0\n",
       "107062           oh your lucky!! its like FREEZING heree      0\n",
       "107063           Night night &quot;Amy&quot; (incognito)      1\n",
       "107064   - or else, there's not much we can do with In...     0\n",
       "107065                              thx for the mention!      1\n",
       "107066    i LOVE abercrombie and fitch.... thats why i...     1\n",
       "107067  So as felicia's mom is cleaning the table, fel...     1\n",
       "107068   I was about 19 and. Got claustrophobic and ha...     1\n",
       "107069    At least Telemundo could leave this baby ali...     0\n",
       "107070    not nice.  ohh, andy murray win wimbeldon, i...     0\n",
       "107071   perhaps you should get a holiday home in the ...     1\n",
       "107072   nightnight my fellow Cappster.....lol sleep t...     1\n",
       "107073                  i know i'm late.....but THANKS!!      1\n",
       "107074  I can hate \" Da Vinci Code \" without even touc...     0\n",
       "\n",
       "[107075 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hiep Nguyen\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, GlobalMaxPool1D,InputLayer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train, y_test=train_test_split(data['text'],data['label'],\n",
    "                                                   test_size=0.2, random_state = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 1000\n",
    "max_len = 150\n",
    "tok = Tokenizer(num_words=max_words,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~123456789')\n",
    "tok.fit_on_texts(list(x_train))\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tok, handle)\n",
    "x_train = tok.texts_to_sequences(x_train)\n",
    "x_test = tok.texts_to_sequences(x_test)\n",
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)\n",
    "y_train = np.array(y_train)\n",
    "y_test =np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 150, 128)          128000    \n",
      "_________________________________________________________________\n",
      "lstm_layer (LSTM)            (None, 150, 128)          131584    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 457,474\n",
      "Trainable params: 457,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 85660 samples, validate on 21415 samples\n",
      "Epoch 1/10\n",
      "85660/85660 [==============================] - 551s 6ms/step - loss: 0.5106 - acc: 0.7440 - val_loss: 0.4718 - val_acc: 0.7664\n",
      "Epoch 2/10\n",
      "85660/85660 [==============================] - 545s 6ms/step - loss: 0.4737 - acc: 0.7679 - val_loss: 0.4725 - val_acc: 0.7703\n",
      "Epoch 3/10\n",
      "85660/85660 [==============================] - 543s 6ms/step - loss: 0.4607 - acc: 0.7777 - val_loss: 0.4610 - val_acc: 0.7733\n",
      "Epoch 4/10\n",
      "85660/85660 [==============================] - 1065s 12ms/step - loss: 0.4524 - acc: 0.7830 - val_loss: 0.4562 - val_acc: 0.7786\n",
      "Epoch 5/10\n",
      "85660/85660 [==============================] - 556s 6ms/step - loss: 0.4422 - acc: 0.7882 - val_loss: 0.4545 - val_acc: 0.7789\n",
      "Epoch 6/10\n",
      "85660/85660 [==============================] - 564s 7ms/step - loss: 0.4350 - acc: 0.7940 - val_loss: 0.4561 - val_acc: 0.7784\n",
      "Epoch 7/10\n",
      "85660/85660 [==============================] - 554s 6ms/step - loss: 0.4259 - acc: 0.7985 - val_loss: 0.4568 - val_acc: 0.7794\n",
      "Epoch 8/10\n",
      "85660/85660 [==============================] - 554s 6ms/step - loss: 0.4185 - acc: 0.8026 - val_loss: 0.4620 - val_acc: 0.7777\n",
      "Epoch 9/10\n",
      "85660/85660 [==============================] - 552s 6ms/step - loss: 0.4124 - acc: 0.8063 - val_loss: 0.4644 - val_acc: 0.7782\n",
      "Epoch 10/10\n",
      "85660/85660 [==============================] - 553s 6ms/step - loss: 0.4027 - acc: 0.8108 - val_loss: 0.4655 - val_acc: 0.7751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e45e9af748>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=to_categorical(y_train,2)\n",
    "y_test=to_categorical(y_test,2)\n",
    "\n",
    "def lstm_model():\n",
    "    d=0.5\n",
    "    model=Sequential()\n",
    "    model.add(InputLayer(input_shape=(x_train.shape[1],)))\n",
    "    model.add(Embedding(max_words,128))\n",
    "    model.add(LSTM(128,return_sequences=True,name='lstm_layer'))\n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(d))\n",
    "    model.add(Dense(2,activation='sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
    "model=lstm_model()\n",
    "model.fit(x_train,y_train, batch_size=32, epochs=10, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
